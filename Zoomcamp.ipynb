{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c15cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys\n",
    "from time import time\n",
    "import pandas as pd \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fe0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveDataToDatabase(params):\n",
    "    user = params.user\n",
    "    password = params.password\n",
    "    host = params.host\n",
    "    port = params.port\n",
    "    db = params.db\n",
    "    tb = params.tb\n",
    "    \n",
    "    # Get the name of the file from url\n",
    "    # file_name = url.rsplit('/', 1)[-1].strip()\n",
    "    file_name = 'E:\\Downloads\\green_tripdata_2019-10.csv\\green_tripdata_2019-10.csv'\n",
    "    # print(f'Downloading {file_name} ...')\n",
    "    # Download file from url\n",
    "    # os.system(f'curl {url.strip()} -o {file_name}')\n",
    "    print('\\n')\n",
    "\n",
    "    # Create SQL engine\n",
    "    engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{db}')\n",
    "\n",
    "    # Read file based on csv or parquet\n",
    "    if '.csv' in file_name:\n",
    "        df = pd.read_csv(file_name, nrows=10)\n",
    "        df_iter = pd.read_csv(file_name, iterator=True, chunksize=100000)\n",
    "    elif '.parquet' in file_name:\n",
    "        file = pq.ParquetFile(file_name)\n",
    "        df = next(file.iter_batches(batch_size=10)).to_pandas()\n",
    "        df_iter = file.iter_batches(batch_size=100000)\n",
    "    else: \n",
    "        print('Error. Only .csv or .parquet files allowed.')\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "    # Create the table\n",
    "    df.head(0).to_sql(name=tb, con=engine, if_exists='replace')\n",
    "\n",
    "\n",
    "    # Insert values\n",
    "    t_start = time()\n",
    "    count = 0\n",
    "    for batch in df_iter:\n",
    "        count+=1\n",
    "\n",
    "        if '.parquet' in file_name:\n",
    "            batch_df = batch.to_pandas()\n",
    "        else:\n",
    "            batch_df = batch\n",
    "\n",
    "        print(f'inserting batch {count}...')\n",
    "\n",
    "        b_start = time()\n",
    "        batch_df.to_sql(name=tb, con=engine, if_exists='append')\n",
    "        b_end = time()\n",
    "\n",
    "        print(f'inserted! time taken {b_end-b_start:10.3f} seconds.\\n')\n",
    "        \n",
    "    t_end = time()   \n",
    "    print(f'Completed! Total time taken was {t_end-t_start:10.3f} seconds for {count} batches.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fd6fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "inserting batch 1...\n",
      "inserted! time taken     11.590 seconds.\n",
      "\n",
      "inserting batch 2...\n",
      "inserted! time taken      8.249 seconds.\n",
      "\n",
      "inserting batch 3...\n",
      "inserted! time taken      8.097 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Infra\\AppData\\Local\\Temp\\ipykernel_12616\\336897551.py:40: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for batch in df_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting batch 4...\n",
      "inserted! time taken      8.478 seconds.\n",
      "\n",
      "inserting batch 5...\n",
      "inserted! time taken      5.817 seconds.\n",
      "\n",
      "Completed! Total time taken was     44.164 seconds for 5 batches.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Args = namedtuple('Args', ['user', 'password', 'host', 'port', 'db', 'tb'])\n",
    "\n",
    "args = Args(user = 'postgres', password = 'postgres', host = 'localhost', port = '5433', db = 'ny_taxi', tb = 'yellow_taxi_trips')\n",
    "\n",
    "\n",
    "moveDataToDatabase(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e8b15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@localhost:5433/ny_taxi')\n",
    "engine.connect()\n",
    "\n",
    "df_zones = pd.read_csv(r\"E:\\Downloads\\taxi_zone_lookup.csv\")\n",
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa058d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
